
<!-- saved from url=(0037)http://cnnlocalization.csail.mit.edu/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>DOSE-IITD</title>

<script async="" src="./mall-iitd/analytics.js.download"></script><script type="text/javascript" src="./mall-iitd/jquery.mlens-1.0.min.js.download"></script>
<script type="text/javascript" src="./mall-iitd/jquery.js.download"></script>
<style>
body
{
    font-family : Arial;
	background-color : #111;
}
.content
{
    width : 800px;
    padding : 25px 50px;
    margin : 25px auto;
    background-color : #fff;
    box-shadow: 0px 0px 10px #999;
    border-radius: 15px; 
}

.contentblock
{
    width : 950px;
    margin : 0 auto;
    padding : 0;
    border-spacing : 25px 0;
}

.contentblock td
{
    background-color : #fff;
    padding : 25px 50px;
    vertical-align : top;
    box-shadow: 0px 0px 10px #999;
    border-radius: 15px; 
}

a, a:visited
{
    color: #224b8d;
}

#authors
{
    text-align : center;
    margin-bottom : 20px;
}

#conference
{
    text-align : center;
    margin-bottom : 20px;
    font-style : italic;
}

#authors a 
{
    margin : 0 10px;
}

h1
{
    text-align : center;
    font-family : Arial;
    font-size : 20px;
}

code
{
	display : block;
	padding : 10px;
	margin : 10px 10px;
}
p code
{
    display : inline;
    padding : 0;
    margin : 0;
}
#teasers
{
    margin : 0 auto;    
}

#teasers td
{
    margin : 0 auto;
    text-align : center;
    padding : 5px;
}

#teasers img
{
    width : 250px; 
}

#results img
{
    width : 133px;
}

#seeintodark {
    margin : 0 auto;
}

#sift 
{
    margin : 0 auto;
}

#sift img
{
    width : 250px;
}

.downloadpaper 
{
    padding-left : 20px;
    float : right;
    text-align : center;
}

.downloadpaper a 
{
    font-weight : bold;
    text-align : center;
}

#demoframe
{
    border : 0;
    padding : 0;
    margin : 0;
    width : 100%;
    height : 340px;
}

#feedbackform
{
    border : 1px solid #ccc;
    margin : 0 auto;
    border-radius : 15px;
}

#eyeglass {
    height : 530px;
}

#eyeglass #wrapper {
    position: relative;
    height: auto;
    margin: 0 auto;
    float: left;
    width : 800px;
}

#mitnews
{ 
    font-weight : normal;
    margin-top : 20px;
    font-size : 12px;
    width : 220px;
}

#mitnews a {
    font-weight : normal;
}
</style>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-23931362-6', 'auto');
  ga('send', 'pageview');

</script>

</head>

<body data-new-gr-c-s-check-loaded="14.1039.0" data-gr-ext-installed="">

<div class="content">

<h1>Towards Domain-Aware Knowledge Distillation for Continual Model Generalization</h1>
<p id="authors">
<a href=mailto:nikhil.jangamreddy@uqidar.iitd.ac.in>Nikhil Reddy</a><sup>a,b</sup> 
<a href="">Mahsa Baktashmotlagh</a><sup>b </sup> 
<a href="">Chetan Arora</a><sup>a </sup> 
<br>
<br>
<sup> a </sup> Indian Institute of Technology, Delhi <br>
<sup> b </sup> The University of Queensland, Australia.
</p>

<div class="downloadpaper">
<a href="./mall-iitd/architechture.png"><img src="./mall-iitd/architechture.png" width="400px" border="2"></a>
</div>

<p>Generalization on unseen domains is critical for Deep Neural Networks (DNNs) to perform well in real-world applications such as autonomous navigation. 
    However, catastrophic forgetting limits the ability of domain generalization and unsupervised domain adaption approaches to adapt to constantly changing target domains. To overcome these challenges, We propose DoSe framework, a Domain-aware Self-Distillation method based on batch normalization prototypes to facilitate continual model generalization across varying target domains. Specifically, we enforce the consistency of batch normalization statistics between two batches of images sampled from the same target domain distribution between the student and teacher models. To alleviate catastrophic forgetting, we introduce a novel exemplar-based replay buffer to identify difficult samples for the model to retain the knowledge.  Specifically, we demonstrate that identifying difficult samples and updating the model periodically using them can help in preserving knowledge learned from previously seen domains. We conduct extensive experiments on two real-world datasets ACDC, C-Driving, and one synthetic dataset SHIFT to verify the efficiency of the proposed DoSe framework. On ACDC, our method outperforms existing SOTA in Domain Generalization, Unsupervised Domain Adaptation, and Daytime settings by 26%, 14%, and 70% respectively.</p>

<p><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Reddy_Towards_Domain-Aware_Knowledge_Distillation_for_Continual_Model_Generalization_WACV_2024_paper.pdf" target="_blank">Paper</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://openaccess.thecvf.com/content/WACV2024/supplemental/Reddy_Towards_Domain-Aware_Knowledge_WACV_2024_supplemental.pdf" target="_blank">Supplementary</a></p>


<br clear="all">
</div>







<!--div class="content" id="references">

<h2>Reference</h2>

<p>B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. CVPR'16 (arXiv:1512.04150, 2015).</p>

<code>
@article{zhou2015cnnlocalization,<br>
&nbsp;&nbsp;title={{Learning Deep Features for Discriminative Localization.}},<br>
&nbsp;&nbsp;author={Zhou, B. and Khosla, A. and Lapedriza. A. and Oliva, A. and Torralba, A.},<br>
&nbsp;&nbsp;journal={CVPR},<br>
&nbsp;&nbsp;year={2016}<br>
}
</code>

<p>Acknowledgement: <br>This work was supported by NSF grant IIS-1524817, and by a Google faculty research award to A.T.</p>

<p></p><center><a href="https://accessibility.mit.edu/"><b>Accessibility</b></a></center><p></p>
</div-->

</body>
</html>
